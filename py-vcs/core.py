import os
import hashlib
import pickle
import datetime
import json

def init_vcs():
    os.makedirs('.vcs_storage', exist_ok = True)
    try:
        with open('.vcs_storage/vcs_log.txt', 'w') as f:
            pass
    except FileExistsError:
        print("Log already initialized")
        
    print("VCS Initialized")
    
def snapshot(directory):
    # Get commit message
    message = input("Write a snapshot message or hit enter to skip. ")
    
    # Create a SHA-256 object to compute directory's unique hash
    snapshot_hash = hashlib.sha256()
    # Create dict to hold snapshot data with a sub dictionary to hold file contents
    snapshot_data = {'files':{}}
    
    # Walk through directory, capture directory tree and files
    for root, dirs, files in os.walk(directory):
        for file in files:
            #Skip files in .vsc_storage
            if '.vcs_storage' in os.path.join(root, file):
                continue
            # Construct full path
            file_path = os.path.join(root, file)
            #Open and read file's content in binary mode (?)
            with open(file_path, 'rb') as f:
                content = f.read()
                # Update the hash object with the string generated by 
                # reading the bytes of the opened file
                snapshot_hash.update(content)
                # Inside 'files' field of snapshot data dict, add a field with 
                # the file path as the name and make its value the content of 
                # the file. Recall that the 'files' key's value is a dict.
                snapshot_data['files'][file_path] = content
       
    # hexdigest() 'finalizes' the hash after you've added all of the contents 
    # of all of the files in all of the files and directories in the root to the hash object         
    hash_digest = snapshot_hash.hexdigest()
    
    # Save the list of files from the snapshot by accessing the keys of the 
    # 'files' dict (which is the file_path for each file we iterated over in the nested for loop)
    snapshot_data['file_list'] = list(snapshot_data['files'].keys())
    
    snapshot_log = snapshot_data
    snapshot_log['files_txt'] = {}
    for key, value in snapshot_log['files'].items():
        snapshot_log['files_txt'][key] = value.decode('utf-8')
        
    log_keys = ['files_txt', 'files_list']
    snapshot_log_final = {key: snapshot_log[key] for key in log_keys if key in snapshot_log}
    snapshot_log_final['message'] = message
    
    with open('.vcs_storage/vcs_log.txt', 'a') as f:
        
        f.write(f'Snapshot Time Stamp: {datetime.datetime.now()}\n')
        f.write(json.dumps(snapshot_log_final, indent=4))
        f.write("\n\n")
                    
    # Save the snapshot data as a pickle file (I think these files are small and can hold a lot 
    # of info? Need to read more about why we use these) and name the file with it's generated hash.
    # Naming it by its hash allows us to easily compare it with other snapshots and see if they are 
    # different at all
    with open(f'.vcs_storage/{hash_digest}', 'wb') as f:
        pickle.dump(snapshot_data, f)

    # Print confirmation with the hash
    print(f"Snapshot created with hash {hash_digest} \nTimestamp: {datetime.datetime.now()}")
    
### REVERTING TO A SNAPSHOT
# To revert to a snapshot, we have to load the pickled data, restore each files content 
# (which we have saved in a dict), and remove any files that aren't present in the snapshot. 

def revert_to_snapshot(hash_digest):
    # Build snapshot path given its hash
    snapshot_path = f'.vcs_storage/{hash_digest}'
    # Check if the snapshot exists
    if not os.path.exists(snapshot_path):
        print("Snapshot doesn't exist.")
        return
    
    # Load the snapshot data from the pickled file
    with open(snapshot_path, 'rb') as f:
        snapshot_data = pickle.load(f)
    
    # Iterate over dict, to pull out file path and content, 
    # at each iteration, use os to create the file and name 
    # it appropriately
    for file_path, content in snapshot_data['files'].items():
        # Check if folder of file exists, and create if not
        os.makedirs(os.path.dirname(file_path), exist_ok = True)
        # Overwrite the content in the file (if it exists) 
        # or make the file if it was deleted
        with open(file_path, 'wb') as f:
            f.write(content)
    
    # Iterate over directory, note all files that are in 
    # directory. Then create a set of files that are in directory but not in snapshot by 
    # subtracting snapshot files from current set, then delete all files 
    # in that set so directory matches snapshot
    # We use a set because there won't be duplicate files 
    # and we only care about membership not order so using a set is more performant and allows for math-like operations
    current_files = set()
    # Walk through directory
    for root, dirs, files, in os.walk('.', topdown = True):
        if '.vcs_storage' in root:
            continue
        for file in files:
            current_files.add(os.path.join(root, file))
            
    # Create a set of files that were in snapshot
    snapshot_files = set(snapshot_data['file_list'])
    
    # Find difference between snapshot_files and current_files to find files that currently
    # exist but didn't exist in the snapshot
    files_to_delete = current_files - snapshot_files
    
    # Iterate through set of files to delete and delete from directory
    for file_path in files_to_delete:
        os.remove(file_path)
        # Confirm message
        print(f"Removed {file_path}")
        
    #Confirmation of successfully reverting to snapshot
    print(f"Reverted to snapshot {hash_digest}")
    
    
if __name__ == "__main__":
    import sys
    #Store command as first word after file name?
    command = sys.argv[1]
    
    if command == "init":
        init_vcs()
    elif command == "snapshot":
        snapshot('.')
    elif command == "revert":
        # Second arg should be hash name of snapshot
        revert_to_snapshot(sys.argv[2])
    else:
        print("unknown command")